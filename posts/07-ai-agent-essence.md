---
title: "AI 개발 방법론 7 - 에이전트의 본질"
date: "2026-01-10"
category: "methodology"
description: "패턴 매칭의 함정에서 벗어나 진짜 에이전트를 이해하기까지. 폴링고 리뉴얼과 회사 프로젝트에서 얻은 깨달음"
tags: ["ai-first", "methodology", "agent", "vibe-coding", "tool-use"]
author: "Su"
lang: "ko"
---

# 에이전트의 본질

> 이전 편: [AI 개발 방법론 6 - 전체를 먼저 보는 개발](06-ai-task-size-consistency.md)

## 회사 에이전트 개편 프로젝트

회의실 예약 서비스를 에이전트로 개편하는 작업을 제안했습니다.

기존에 회의실 예약 API는 다 있었습니다. 여기에 사내문서 검색을 추가하려고 했는데, 어차피 RAG랑 벡터 그래프를 쓰는 김에 아예 에이전트화를 해보자고 범위를 확장했습니다.

검색을 하다 보니 RAG만으로는 부족하고 온톨로지를 같이 사용하는 게 좋다는 내용이 있었습니다. 새로운 기술이었지만 부담이 없었습니다. 바이브코딩으로 AI가 개발할 거니까요. fallingo를 개발해오면서 쌓은 노하우에 대한 자신감도 한몫했습니다.

그렇게 개발을 시작했습니다.

---

## 처음 생각한 에이전트

에이전트를 이렇게 이해하고 있었습니다.

"전통적인 서비스 개발에서는 사용자가 UI를 통해 API를 호출한다. 에이전트는 이걸 자연어로 바꾼 것이다. 사용자가 자연어로 말하면, AI가 적절한 API를 호출하고, 결과를 자연어로 풀어서 설명해준다."

그래서 정교한 API 설계가 중요하다고 생각했습니다.

틀렸습니다.

---

## Vibe Framework 문서 작업에서 시작된 의문

회사 개발을 진행하면서 동시에 [Vibe Framework](https://github.com/su-record/vibe)를 업데이트하고 있었습니다. 스킬, 훅, 에이전트 관련 문서들을 작성하고 정리하는 과정이었습니다.

문서를 쓰다 보니 의문이 생겼습니다.

"내가 에이전트라고 생각하는 게 진짜 에이전트 맞나?"

fallingo에 적용된 AI 기능들을 다시 살펴봤습니다. AI 추천, AI 피드 콘텐츠 작성, AI 검수, 폴링고 오피셜. 이것들을 에이전트 서비스라고 생각하고 있었는데요.

검토 결과, 폴링고 오피셜을 제외한 나머지는 전부 API 호출 기반이었습니다. 사용자 입력 → 특정 API 호출 → 결과 반환. AI가 자율적으로 도구를 선택하는 게 아니라, 미리 정해진 API를 호출하는 구조였습니다.

에이전트가 아니었습니다.

---

## 진짜 에이전트란

깨달음이 왔습니다.

```
내가 생각한 것: 사용자 자연어 → AI가 API 매핑 → 결과 설명
```

이건 "AI-powered 인터페이스"입니다. 기존 서비스에 자연어 레이어를 씌운 것일 뿐입니다.

```
진짜 에이전트: 사용자 목표 → AI가 스스로 판단 → 필요한 도구들 조합 
              → 중간 결과 보고 다음 행동 결정 → 최종 수행
```

핵심 차이는 자율성입니다.

AI-powered 인터페이스는 "이 API 호출해줘"라고 하면 호출합니다. 에이전트는 "이거 해줘"라고 하면 뭘 호출할지, 몇 번 할지, 어떤 순서로 할지 AI가 판단합니다.

이걸 이해하고 fallingo AI 추천 기능을 에이전트로 리뉴얼했습니다. 피드 콘텐츠 작성이나 검수는 전체 작업 플로우 중 일부분이라 기존 API 호출 방식이 맞았고요.

---

## 회사 코드 리팩토링, 그리고 테스트

에이전트 개념을 제대로 이해하고 회사 코드도 리팩토링했습니다.

그리고 오늘, AI API 키 발급이 완료되어 테스트를 시작했습니다.

문제가 있었습니다. 계속 기대한 대로 동작하지 않았습니다.

```
나: "김OO님은?"
에이전트: "죄송합니다. 김OO님의 정보를 찾을 수 없습니다.
          - 이름이 정확하지 않을 수 있습니다
          - 해당 직원이 조직에 없을 수 있습니다"
```

분명히 있는 직원인데 "없다"고 합니다. 수정을 요청하고, 수정되는 과정을 모니터링하다가 발견했습니다.

```python
# AI가 구현한 라우팅 프롬프트
"""
**관계 질문 패턴 (반드시 organization으로 분류):**
- "~의 팀장은 누구야?", "~의 상사는?"
- "~와 같은 부서/팀 사람은?"
- "~팀 인원 알려줘", "~팀에 누가 있어?"
"""
```

LLM을 사용하긴 했지만, 프롬프트 자체가 **패턴 목록을 나열하는 방식**이었습니다. "김OO님은?"이라는 질문은 저 패턴 어디에도 해당하지 않았습니다. LLM이 패턴에 없는 질문을 받으니 제대로 분류하지 못한 겁니다.

랭그래프 구조 자체는 제대로 만들어져 있었습니다. 인사관리, 회의실 예약, 사내문서 검색 노드가 그래프로 연결되어 있었고요. 문제는 라우팅 프롬프트가 **패턴 기반 사고방식**으로 작성되어 있었다는 점입니다.

---

## 패턴 기반에서 의미 기반으로

프롬프트를 **의미 기반**으로 다시 작성했습니다.

```python
# 수정된 라우팅 프롬프트
"""
**Step 1: 핵심 주제 파악**
문장에서 핵심 주제가 무엇인가?
- 사람/조직/관계 → organization

**중요**: 사람 이름이 포함되면 대부분 organization입니다!
"""
```

패턴 목록을 외우게 하는 대신, **어떻게 생각해야 하는지**를 알려줬습니다.

```
수정 후:
나: "김OO님은?"
에이전트: "김OO (수석)
          - 부서: 기술개발부
          - 이메일: xxx@company.com
          김OO님은 기술개발부 소속 수석으로 근무하고 계십니다."
```

정상적으로 동작했습니다.

| 패턴 기반 프롬프트 | 의미 기반 프롬프트 |
|----------|-----------|
| 패턴 목록에 없으면 실패 | 의미를 파악해서 분류 |
| 새로운 표현마다 패턴 추가 필요 | 원칙만 이해하면 유연하게 대응 |
| "이 패턴들 외워" | "이렇게 생각해" |

이게 요즘 Agent 아키텍처의 표준 방식입니다. OpenAI function calling, Claude tool use 모두 LLM이 의미를 파악해서 도구를 선택합니다.

---

## 도구(Tool)의 본질

이 과정에서 "도구"가 뭔지도 명확해졌습니다.

처음엔 막연했습니다. Claude 스킬이나 MCP가 그런 역할인 것 같긴 한데, 정확히 설명하기 어려웠습니다.

도구는 AI가 호출할 수 있는 함수입니다.

```python
def get_weather(city: str) -> str:
    """도시의 날씨를 조회합니다"""
    ...

def search_restaurants(location: str, cuisine: str) -> list:
    """음식점을 검색합니다"""
    ...

def create_reservation(restaurant_id: str, date: str, people: int) -> dict:
    """예약을 생성합니다"""
    ...
```

AI에게 "이런 도구들 있어, 설명은 이래"라고 알려주면 → AI가 언제 뭘 쓸지 판단해서 호출합니다.

Claude 스킬, MCP, function calling 모두 같은 개념입니다.

1. 도구 정의 (이름, 설명, 파라미터)
2. AI가 선택 & 호출
3. 결과 받아서 다음 행동 결정

이걸 이해하니까 관점이 바뀌었습니다.

~~"이 기능 API 어떻게 설계하지?"~~

**"AI한테 어떤 도구들 줄까?"**

---

## 남은 의문들

정상 동작은 하는데, 의문이 남았습니다.

"LLM이 직접 도구 선택하면 되는데, 랭그래프는 왜 필요하지? 온톨로지는? RAG는?"

현재 이해한 바로는 이렇습니다.

| 기술 | 역할 |
|------|------|
| **LLM 라우팅** | "어떤 도구 쓸지" 판단 |
| **랭그래프** | 복잡한 멀티스텝 흐름 관리 (A→B→C 순서, 분기, 루프) |
| **온톨로지** | 도메인 지식 구조화 (회의실-층-건물 관계 등) |
| **RAG** | 외부 문서에서 관련 정보 검색해서 컨텍스트 제공 |

지금 구현에서 단순 도구 선택은 LLM 라우팅으로 충분했습니다. 랭그래프는 현재 플로우가 복잡하지 않아서 오버엔지니어링일 수 있고요.

온톨로지와 RAG는 사내문서 검색 테스트를 하면서 더 알 수 있을 것 같습니다. "회의실 예약 규정"을 찾으려면 RAG가 필요하고, "3층 회의실이 본관 소속이다"를 알려면 온톨로지가 필요할 테니까요.

아직 모르는 게 많습니다. 하지만 계속 부딪히면서 알아가는 중입니다.

---

## 거품 빼기

에이전트 개발에 대해 검색하면 진입장벽이 높아 보입니다.

"풀스택이어야 한다." "랭체인이랑 랭그래프를 알아야 한다." "온톨로지, RAG, 벡터 DB 지식이 필요하다."

솔직히 저는 이것들을 깊이 모릅니다.

그런데 잘못된 구현을 발견하고, 더 나은 방식으로 수정했습니다. 이론을 몰라도 실전에서 문제를 찾고 해결했습니다.

핵심은 특정 프레임워크 숙련도가 아닙니다. "AI한테 뭘 시킬지 판단하는 능력"입니다.

---

## 결론

이번 경험에서 얻은 것들입니다.

**바이브코딩과 에이전트 구현은 진입장벽이 동일합니다.** 누구나 시작할 수 있습니다.

**좋은 에이전트의 전제 조건:**

> "무엇을 어떻게 사용하고 싶은지 AI에게 잘 설명할 수 있어야 한다"

이건 프롬프트 엔지니어링이 아닙니다. 도메인 이해 + 명확한 의사소통입니다.

**하지만 품질 보장이 진짜 과제입니다.**

바이브코딩으로 만든 코드도 검증이 필요합니다. AI가 패턴 매칭으로 구현해놓은 걸 발견한 것처럼요. 그래서 [Vibe Framework](https://github.com/su-record/vibe)를 계속 업데이트하고 있습니다.

RAG 테스트가 끝나면 더 많은 걸 알게 될 것 같습니다.

---

> 이전 편: [AI 개발 방법론 6 - 전체를 먼저 보는 개발](06-ai-task-size-consistency.md)

**fallingo 베타 런칭이 다가오고 있습니다.**