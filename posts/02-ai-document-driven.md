---
title: "AI를 위한 문서 작성법 - 왜 일관성이 무너졌을까?"
date: "2025-11-10"
category: "methodology"
description: "AI가 읽고 일할 수 있는 문서를 만들기까지의 시행착오와 깨달음. 그리고 바이브코딩을 위한 MCP 도구를 만들다"
tags: ["ai-first", "prd", "documentation", "claude", "mcp"]
author: "Su"
lang: "ko"
---

# AI를 위한 문서 작성법 - 왜 일관성이 무너졌을까?

> 이전 편: "9년 전 포기했던 꿈, AI와 함께 다시 꺼내다"

## 첫 번째 성과: 디테일이 없다

첫 Flutter 앱은 몇 시간 만에 완성되었습니다.

하지만 디테일이 없었습니다.

그때 깨달았습니다.

"아! AI가 읽고 개발할 수 있게, **개발 가이드 문서**가 필요한 거구나!"

이런 문서를 **PRD (Product Requirements Document)**라고 한다는 걸 나중에 알았습니다.

난 그런 것도 모르고 시작한 것이었습니다.

## 수십 번의 리셋

그 뒤로 꽤 많은 횟수로 문서를 갈아엎었습니다.

왜냐하면, 문서 준비가 다 됐다는 시점에 검토를 하다 보면 **전체 구성상 일관성이 너무 떨어지는 것**이었습니다.

데이터 모델이나 예제 코드를 다 가진 문서들인데 일관성이 없으니 개발된 소스 코드가 뒤죽박죽이었습니다.

"왜? AI가 작성했는데 일관성이 떨어지지?"

"왜 컨텍스트가 매번 이렇게 달라지는 거지?"

## AI가 바뀐다는 사실

고민 끝에 알게 되었습니다.

**세션이 바뀔 때마다 AI가 바뀐다는 것을.**

그때부턴 AI가 바뀌어도 일관된 작업을 할 수 있는 방법을 고민했습니다.

**Claude의 Project**, **Gemini의 Gem**을 활용했습니다.

문서 작성법, 기획 문서, 개발 코딩 컨벤션, 기술 스택 같은 걸 지침 자료로 등록하고 다시 문서를 작성했습니다.

이전보다는 품질이 괜찮아졌습니다.

하지만 여전히 완벽하진 않았습니다.

## 예제 코드가 문제인가?

문서가 준비되고 개발에 들어가면 여전히 문제가 생기거나, 에러 처리를 못하는 상황이 발생했습니다.

"AI가 개발하는데 예제 코드가 필요한 게 맞나?"

싶어서 그 부분을 다 없애보기도 했습니다.

갖가지 시도를 했지만, 오류가 발생하고 해결이 안 되는 것을 보면서 생각했습니다.

"현재 AI 기술이 가진 한계인가?"

AI가 **항상 요구하지 않은 내용을 자꾸 추가하는 게 문제 발생의 원인**이었습니다.

만약 내가 FastAPI, 백엔드 개발, Flutter에 대한 지식이 있다면 어떻게든 에러를 수정해보려 했을 텐데 그럴 수 없었습니다.

## 바이브코딩을 위한 도구가 필요하다

fallingo 백엔드 API를 개발하던 중이었습니다.

FastAPI로 RESTful 엔드포인트를 구현하고, Redis 캐싱 전략을 짜고, BackgroundTasks로 FCM 알림을 비동기 처리하는 복잡한 아키텍처를 다루고 있었죠.

Claude와 함께 코딩하면서(바이브코딩) 반복되는 패턴을 발견했습니다:
- "이 API 엔드포인트의 성능 병목 지점을 찾아줘"<br />
- "이 함수의 복잡도를 분석하고 리팩토링 제안해줘"

**"바이브코딩에 특화된 도구가 있으면 좋겠다"**

## MCP를 만들다

그렇게 탄생한 것이 **hi-ai MCP**입니다.

**MCP (Model Context Protocol)**는 Claude가 제공하는 확장 프로토콜입니다. AI가 외부 도구나 데이터에 접근할 수 있게 해주죠.

hi-ai MCP는 바이브코딩을 위한 코드 분석 도구입니다:

### 핵심 기능

1. **코드 복잡도 분석**
   - Cyclomatic Complexity 측정<br />
   - Halstead Metrics 계산<br />
   - Maintainability Index 평가

2. **의존성 분석**
   - Import/Export 관계 시각화<br />
   - 순환 의존성 탐지<br />
   - 사용하지 않는 의존성 찾기

3. **코드 품질 검사**
   - 중복 코드 탐지<br />
   - 코딩 컨벤션 검증<br />
   - 보안 취약점 스캔

4. **리팩토링 제안**
   - AI 기반 개선 제안<br />
   - 성능 최적화 포인트<br />
   - 테스트 커버리지 분석

### 왜 만들었나?

바이브코딩을 하다 보면 AI에게 같은 질문을 반복하게 됩니다.

"이 코드 복잡도 어때?"
"이 파일 의존성 어떻게 돼?"
"이거 리팩토링 해야 할까?"

MCP를 만들면 AI가 **직접 코드를 분석**할 수 있습니다. 내가 일일이 물어보지 않아도요.

### 실제 사용 예시

```
나: "백엔드 API 성능 병목 지점 찾아줘"

Claude (hi-ai MCP 사용):
- feed_service.py: Complexity 23 (높음)
- 캐싱 미적용 함수 3개 발견
- N+1 쿼리 문제 2곳 감지

개선 제안:
1. get_feed_list() Redis 캐싱 추가
2. get_user_feeds()를 배치 쿼리로 변경
3. calculate_tier() 함수 분리 (SRP 위반)
```

AI가 알아서 분석하고 제안합니다.

## 포기하려던 순간

그래도 여전히 fallingo 개발은 막혔습니다.

DB 스키마와 모델이 일관성을 갖지 못하니까 수정하고 하는데 **돈만 들더라고요.**

MCP를 만드는 건 재미있었지만, 정작 fallingo는 앞으로 나아가지 못했습니다.

그래도 내가 질문하는 그리고 요구사항을 전달하는 **내 능력이 더 문제라고 생각**했습니다.

AI와 대화를 통해 더 나은 방법을 찾아보려고 했습니다.

지금까지의 실패에 대해 설명했습니다.

---

포기하려던 그 순간, AI가 새로운 방법을 제안했습니다.

> 다음 편: "AI와 협업하는 새로운 방법론 - 일관성 문제를 해결하다"
